{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkhuran3/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-27 16:13:23.835498: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-27 16:13:23.838750: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 16:13:23.879014: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-27 16:13:23.879037: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-27 16:13:23.880608: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-27 16:13:23.888763: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 16:13:24.647166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from datasets import load_metric\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pickle\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import sklearn\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Add, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 16:14:10.422164: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_20 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_21 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_22 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_23 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_25 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_26 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_27 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_29 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_30 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_31 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_32 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_33 (InputLayer)       [(None, 20)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_34 (InputLayer)       [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_35 (InputLayer)       [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " input_36 (InputLayer)       [(None, 100)]                0         []                            \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)      multiple                     1094822   ['input_19[0][0]',            \n",
      "                                                          40         'input_20[0][0]',            \n",
      "                                                                     'input_21[0][0]',            \n",
      "                                                                     'input_22[0][0]',            \n",
      "                                                                     'input_23[0][0]',            \n",
      "                                                                     'input_24[0][0]',            \n",
      "                                                                     'input_25[0][0]',            \n",
      "                                                                     'input_26[0][0]',            \n",
      "                                                                     'input_27[0][0]',            \n",
      "                                                                     'input_28[0][0]',            \n",
      "                                                                     'input_29[0][0]',            \n",
      "                                                                     'input_30[0][0]',            \n",
      "                                                                     'input_31[0][0]',            \n",
      "                                                                     'input_32[0][0]',            \n",
      "                                                                     'input_33[0][0]',            \n",
      "                                                                     'input_34[0][0]',            \n",
      "                                                                     'input_35[0][0]',            \n",
      "                                                                     'input_36[0][0]']            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6  (None, 768)                  0         ['bert[0][0]']                \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7  (None, 768)                  0         ['bert[1][0]']                \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8  (None, 768)                  0         ['bert[2][0]']                \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9  (None, 768)                  0         ['bert[3][0]']                \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 768)                  0         ['bert[4][0]']                \n",
      " 0 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 768)                  0         ['bert[5][0]']                \n",
      " 1 (GlobalAveragePooling1D)                                                                       \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, 32)                   24608     ['global_average_pooling1d_6[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, 32)                   24608     ['global_average_pooling1d_7[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, 32)                   24608     ['global_average_pooling1d_8[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, 32)                   24608     ['global_average_pooling1d_9[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, 32)                   24608     ['global_average_pooling1d_10[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dense_25 (Dense)            (None, 256)                  196864    ['global_average_pooling1d_11[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)        (None, 32)                   0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)        (None, 32)                   0         ['dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)        (None, 32)                   0         ['dense_19[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)        (None, 32)                   0         ['dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)        (None, 32)                   0         ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)        (None, 256)                  0         ['dense_25[0][0]']            \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, 8)                    264       ['dropout_44[0][0]']          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, 8)                    264       ['dropout_45[0][0]']          \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, 8)                    264       ['dropout_46[0][0]']          \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, 8)                    264       ['dropout_47[0][0]']          \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, 8)                    264       ['dropout_48[0][0]']          \n",
      "                                                                                                  \n",
      " dense_26 (Dense)            (None, 64)                   16448     ['dropout_49[0][0]']          \n",
      "                                                                                                  \n",
      " additional_features (Input  [(None, 33)]                 0         []                            \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenat  (None, 104)                  0         ['dense_16[0][0]',            \n",
      " e)                                                                  'dense_18[0][0]',            \n",
      "                                                                     'dense_20[0][0]',            \n",
      "                                                                     'dense_22[0][0]',            \n",
      "                                                                     'dense_24[0][0]',            \n",
      "                                                                     'dense_26[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 104)                  3536      ['additional_features[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenat  (None, 208)                  0         ['concatenate_42[0][0]',      \n",
      " e)                                                                  'dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  26752     ['concatenate_43[0][0]']      \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)        (None, 128)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64)                   8256      ['dropout_37[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)        (None, 64)                   0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 512)                  33280     ['dropout_38[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)        (None, 512)                  0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 256)                  131328    ['dropout_39[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 1)                    257       ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110023321 (419.71 MB)\n",
      "Trainable params: 203409 (794.57 KB)\n",
      "Non-trainable params: 109819912 (418.93 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"/home/tkhuran3/L/colbert_trained_w_features\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df= pd.read_csv(\"/home/tkhuran3/LOLgarithm/dataset/reddit_test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>...</th>\n",
       "      <th>repetition</th>\n",
       "      <th>sense_combination_score</th>\n",
       "      <th>farmost_path</th>\n",
       "      <th>closest_path</th>\n",
       "      <th>alliteration</th>\n",
       "      <th>max_alliteration</th>\n",
       "      <th>rhyme</th>\n",
       "      <th>max_rhyme</th>\n",
       "      <th>jokes</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893706</td>\n",
       "      <td>0.655792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875066</td>\n",
       "      <td>0.997015</td>\n",
       "      <td>A Family of 4, A Dad, A Mom, A Son and A Daugh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978674</td>\n",
       "      <td>0.996129</td>\n",
       "      <td>0.991066</td>\n",
       "      <td>0.987655</td>\n",
       "      <td>0.996389</td>\n",
       "      <td>0.957694</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979607</td>\n",
       "      <td>Give a man a fire and he is warm for the night...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993228</td>\n",
       "      <td>0.986217</td>\n",
       "      <td>0.992791</td>\n",
       "      <td>0.970797</td>\n",
       "      <td>0.988942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>She avoided my eye contact,_____[removed]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982541</td>\n",
       "      <td>0.997842</td>\n",
       "      <td>0.988132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989010</td>\n",
       "      <td>0.993191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>No Homo_____[deleted]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.024837</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.038562</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980982</td>\n",
       "      <td>0.987449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995524</td>\n",
       "      <td>0.987528</td>\n",
       "      <td>0.994414</td>\n",
       "      <td>0.980277</td>\n",
       "      <td>0.996589</td>\n",
       "      <td>Watching Childbith_____The nurse approached hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      fear     anger  anticipation     trust  surprise  positive  \\\n",
       "0           0  0.000000  0.000000      0.000000  0.009009  0.000000  0.036036   \n",
       "1           1  0.074074  0.000000      0.000000  0.000000  0.000000  0.037037   \n",
       "2           2  0.000000  0.000000      0.000000  0.000000  0.000000  0.200000   \n",
       "3           3  0.000000  0.000000      0.000000  0.000000  0.000000  0.000000   \n",
       "4           4  0.003660  0.003922      0.006209  0.024837  0.002549  0.038562   \n",
       "\n",
       "   negative   sadness   disgust  ...  repetition  sense_combination_score  \\\n",
       "0  0.000000  0.000000  0.000000  ...    1.000000                 0.893706   \n",
       "1  0.000000  0.000000  0.000000  ...    0.978674                 0.996129   \n",
       "2  0.000000  0.000000  0.000000  ...    0.993228                 0.986217   \n",
       "3  0.000000  0.000000  0.000000  ...    1.000000                 0.982541   \n",
       "4  0.005229  0.004575  0.003268  ...    0.980982                 0.987449   \n",
       "\n",
       "   farmost_path  closest_path  alliteration  max_alliteration     rhyme  \\\n",
       "0      0.655792      1.000000      0.992425          1.000000  0.875066   \n",
       "1      0.991066      0.987655      0.996389          0.957694  1.000000   \n",
       "2      0.992791      0.970797      0.988942               NaN  1.000000   \n",
       "3      0.997842      0.988132      1.000000          0.989010  0.993191   \n",
       "4      1.000000      0.995524      0.987528          0.994414  0.980277   \n",
       "\n",
       "   max_rhyme                                              jokes  labels  \n",
       "0   0.997015  A Family of 4, A Dad, A Mom, A Son and A Daugh...       0  \n",
       "1   0.979607  Give a man a fire and he is warm for the night...       0  \n",
       "2   1.000000          She avoided my eye contact,_____[removed]       0  \n",
       "3   1.000000                              No Homo_____[deleted]       0  \n",
       "4   0.996589  Watching Childbith_____The nurse approached hi...       0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_input = test_df.iloc[:, 1:-2]\n",
    "test_df_texts = test_df.iloc[:,34:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 33) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(test_df_input.shape, test_df_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jokes</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Family of 4, A Dad, A Mom, A Son and A Daugh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Give a man a fire and he is warm for the night...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She avoided my eye contact,_____[removed]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Homo_____[deleted]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Watching Childbith_____The nurse approached hi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               jokes  labels\n",
       "0  A Family of 4, A Dad, A Mom, A Son and A Daugh...       0\n",
       "1  Give a man a fire and he is warm for the night...       0\n",
       "2          She avoided my eye contact,_____[removed]       0\n",
       "3                              No Homo_____[deleted]       0\n",
       "4  Watching Childbith_____The nurse approached hi...       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_input = test_df_input.values.tolist()\n",
    "array_list = np.array(test_df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "input categories:\n",
      "\t ['jokes']\n",
      "\n",
      "output TARGET_COUNT:\n",
      "\t 1\n",
      "\n",
      "output categories:\n",
      "\t ['labels']\n"
     ]
    }
   ],
   "source": [
    "MAX_SENTENCE_LENGTH = 20\n",
    "MAX_SENTENCES = 5\n",
    "MAX_LENGTH = 100\n",
    "\n",
    "output_categories = list(test_df_texts.columns[[1]])\n",
    "input_categories = list(test_df_texts.columns[[0]])\n",
    "\n",
    "TARGET_COUNT = len(output_categories)\n",
    "\n",
    "print('\\ninput categories:\\n\\t', input_categories)\n",
    "print('\\noutput TARGET_COUNT:\\n\\t', TARGET_COUNT)\n",
    "print('\\noutput categories:\\n\\t', output_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tkhuran3/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "MODEL_TYPE = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_id(str1, str2, truncation_strategy, length):\n",
    "\n",
    "    inputs = tokenizer.encode_plus(str1, str2,\n",
    "        add_special_tokens=True,\n",
    "        max_length=length,\n",
    "        truncation_strategy=truncation_strategy)\n",
    "\n",
    "    input_ids =  inputs[\"input_ids\"]\n",
    "    input_masks = [1] * len(input_ids)\n",
    "    input_segments = inputs[\"token_type_ids\"]\n",
    "    padding_length = length - len(input_ids)\n",
    "    padding_id = tokenizer.pad_token_id\n",
    "    input_ids = input_ids + ([padding_id] * padding_length)\n",
    "    input_masks = input_masks + ([0] * padding_length)\n",
    "    input_segments = input_segments + ([0] * padding_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer):\n",
    "    model_input = []\n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input.append([])\n",
    "    \n",
    "    for _, row in tqdm(df[columns].iterrows()):\n",
    "        i = 0\n",
    "        \n",
    "        # sent\n",
    "        sentences = sent_tokenize(row.jokes)\n",
    "        for xx in range(MAX_SENTENCES):\n",
    "            s = sentences[xx] if xx<len(sentences) else ''\n",
    "            ids_q, masks_q, segments_q = return_id(s, None, 'longest_first', MAX_SENTENCE_LENGTH)\n",
    "            model_input[i].append(ids_q)\n",
    "            i+=1\n",
    "            model_input[i].append(masks_q)\n",
    "            i+=1\n",
    "            model_input[i].append(segments_q)\n",
    "            i+=1\n",
    "        \n",
    "        # full row\n",
    "        ids_q, masks_q, segments_q = return_id(row.jokes, None, 'longest_first', MAX_LENGTH)\n",
    "        model_input[i].append(ids_q)\n",
    "        i+=1\n",
    "        model_input[i].append(masks_q)\n",
    "        i+=1\n",
    "        model_input[i].append(segments_q)\n",
    "        \n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input[xx] = np.asarray(model_input[xx], dtype=np.int32)\n",
    "        \n",
    "    print(model_input[0].shape)\n",
    "    return model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:05, 370.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 20)\n"
     ]
    }
   ],
   "source": [
    "inputs = compute_input_arrays(test_df_texts, input_categories, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 2000 20\n",
      "Give a man a fire and he is warm for the night..._____But set a man on fire and he is warm for the rest of his life.\n",
      "['Give a man a fire and he is warm for the night..._____But set a man on fire and he is warm for the rest of his life.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 101, 2507, 1037, 2158, 1037, 2543, 1998, 2002, 2003, 4010, 2005,\n",
       "        1996, 2305, 1012, 1012, 1012, 1035, 1035, 1035,  102], dtype=int32),\n",
       " array([101, 102,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0], dtype=int32),\n",
       " array([101, 102,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0], dtype=int32),\n",
       " array([ 101, 2507, 1037, 2158, 1037, 2543, 1998, 2002, 2003, 4010, 2005,\n",
       "        1996, 2305, 1012, 1012, 1012, 1035, 1035, 1035, 1035, 1035, 2021,\n",
       "        2275, 1037, 2158, 2006, 2543, 1998, 2002, 2003, 4010, 2005, 1996,\n",
       "        2717, 1997, 2010, 2166, 1012,  102,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0], dtype=int32))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(inputs), len(inputs[0]), len(inputs[0][0]))\n",
    "# check out input for 1st row\n",
    "xx = 1\n",
    "print(test_df_texts.iloc[xx,0])\n",
    "print(sent_tokenize(test_df_texts.iloc[xx,0]))\n",
    "inputs[0][xx], inputs[3][xx], inputs[6][xx], inputs[15][xx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n",
    "\n",
    "outputs = compute_output_arrays(test_df_texts, output_categories)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkhuran3/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103: RuntimeWarning: overflow encountered in cast\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 55s 605ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict((inputs, array_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = outputs\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.611 Prec 0.5817378497790869 Rec 0.79 F1 0.6700593723494487\n"
     ]
    }
   ],
   "source": [
    "print('Acc', accuracy, 'Prec', precision, 'Rec', recall, 'F1',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.43      0.53      1000\n",
      "           1       0.58      0.79      0.67      1000\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.63      0.61      0.60      2000\n",
      "weighted avg       0.63      0.61      0.60      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "model_without = keras.models.load_model(\"/home/tkhuran3/L/colbert-trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 91s 1s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_without.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.499 Prec 0.4994974874371859 Rec 0.994 F1 0.6648829431438127\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print('Acc', accuracy, 'Prec', precision, 'Rec', recall, 'F1',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.00      0.01      1000\n",
      "           1       0.50      0.99      0.66      1000\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.45      0.50      0.34      2000\n",
      "weighted avg       0.45      0.50      0.34      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
