{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40wTiNn2JciN",
        "outputId": "4003d02f-d2c6-4f4f-a6fd-383864d614a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Package cmudict is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import wordnet as wn, cmudict\n",
        "\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import re\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action = 'ignore')\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('cmudict')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "uj0WMTcKJw97"
      },
      "outputs": [],
      "source": [
        "# Read the dataset\n",
        "dataset = pd.read_csv(r\"/content/drive/MyDrive/CSC791:NLP/project/dataset.csv\")\n",
        "# Separate the X(jokes) and the Y(is_humor or not)\n",
        "\n",
        "jokes = list(dataset['text'])\n",
        "labels = list(dataset['humor'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "tAvl_tRIKvj9"
      },
      "outputs": [],
      "source": [
        "def clean_data(jokes):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    PATTERN = r'[^A-Za-z0-9\\s]'\n",
        "\n",
        "    words_list = []\n",
        "    for joke in jokes:\n",
        "        joke = joke.lower()\n",
        "        processed_joke = re.sub(PATTERN, '', joke)\n",
        "        words = processed_joke.split(' ')\n",
        "        words_list.append(words)\n",
        "\n",
        "    return words_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLQ9uI6aKwrD",
        "outputId": "9108a526-81b2-4393-9cd6-92b5460847e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200000"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_list = clean_data(jokes)\n",
        "len(words_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "sZPDhDJaMN04"
      },
      "outputs": [],
      "source": [
        "cbow = Word2Vec(words_list, min_count = 1,\n",
        "                              vector_size = 10, window = 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfkR5lN2NHLd"
      },
      "outputs": [],
      "source": [
        "skip_gram = Word2Vec(words_list, min_count = 1, vector_size = 100,\n",
        "                                             window = 5, sg = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzY_a_6lNcW0"
      },
      "source": [
        "### Incongruity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjhu7Afiuqf3",
        "outputId": "8483fa5d-2418-4e1c-bfa9-4949190fa70e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Sentences: 100%|██████████| 200000/200000 [04:41<00:00, 710.13it/s]\n"
          ]
        }
      ],
      "source": [
        "max_threshold = 1  # Set maximum threshold as 1 because distance of word from itself will be 1\n",
        "disconnection_list = []\n",
        "repetition_list = []\n",
        "for sentence in tqdm(words_list, desc=\"Processing Sentences\"):\n",
        "    sentence_word_distances = []\n",
        "    for i in range(len(sentence)):\n",
        "        for j in range(i + 1, len(sentence)):\n",
        "            distance = cbow.wv.similarity(sentence[i], sentence[j])\n",
        "            if distance < max_threshold:\n",
        "                sentence_word_distances.append(distance)\n",
        "    # Check if the sentence_word_distances list is not empty before calculating disconnection and repetition\n",
        "    if sentence_word_distances:\n",
        "        disconnection = max(sentence_word_distances)\n",
        "        repetition = min(sentence_word_distances)\n",
        "    else:\n",
        "        disconnection = None\n",
        "        repetition = None\n",
        "    disconnection_list.append(disconnection)\n",
        "    repetition_list.append(repetition)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "AMQRq1U3g34n"
      },
      "outputs": [],
      "source": [
        "def incongruity(word2vec_model, words_list):\n",
        "  max_threshold = 1  # Set maximum threshold as 1 because distance of word from itself will be 1\n",
        "  disconnection_list = []\n",
        "  repetition_list = []\n",
        "  for sentence in tqdm(words_list, desc=\"Processing Sentences\"):\n",
        "      sentence_word_distances = []\n",
        "      for i in range(len(sentence)):\n",
        "          for j in range(i + 1, len(sentence)):\n",
        "              distance = word2vec_model.wv.similarity(sentence[i], sentence[j])\n",
        "              if distance < max_threshold:\n",
        "                  sentence_word_distances.append(distance)\n",
        "      # Check if the sentence_word_distances list is not empty before calculating disconnection and repetition\n",
        "      if sentence_word_distances:\n",
        "          disconnection = max(sentence_word_distances)\n",
        "          repetition = min(sentence_word_distances)\n",
        "      else:\n",
        "          disconnection = None\n",
        "          repetition = None\n",
        "      disconnection_list.append(disconnection)\n",
        "      repetition_list.append(repetition)\n",
        "  return disconnection_list, repetition_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ke0N6CCbhGvu",
        "outputId": "4265c207-27ab-485b-b8f1-bda81ce9c5ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Sentences: 100%|██████████| 200000/200000 [05:15<00:00, 634.91it/s]\n"
          ]
        }
      ],
      "source": [
        "disconnection_list, repetition_list = incongruity(cbow, words_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "ZOFoBqF00ryO"
      },
      "outputs": [],
      "source": [
        "incongruity_df = pd.DataFrame({'Disconnection': disconnection_list,\n",
        "    'Repetition': repetition_list\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9VY2ENU4hze"
      },
      "source": [
        "##### Normalize us option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffLc1VWl1TYG",
        "outputId": "ea7f6893-db2f-4a6b-d874-c25a35eda6d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9959833333333333"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "train_data_X, test_data_X, train_data_Y, test_data_Y = train_test_split(incongruity_df, labels, test_size=0.7)\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(train_data_X, train_data_Y)\n",
        "model.score(train_data_X, train_data_Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KVsDZf02fjf",
        "outputId": "031d4c12-cd22-4843-a361-ae7cf2eecacc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.63      0.64      0.64     68894\n",
            "        True       0.65      0.64      0.64     71106\n",
            "\n",
            "    accuracy                           0.64    140000\n",
            "   macro avg       0.64      0.64      0.64    140000\n",
            "weighted avg       0.64      0.64      0.64    140000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(test_data_X)\n",
        "print(classification_report(preds, test_data_Y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIN9QUPo4mm-"
      },
      "source": [
        "### Ambiguity\n",
        "#### 3 Features: Sense combination, closest path similarity, farmos path similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy05gfLa6G5N",
        "outputId": "f5d9f1f2-f9b8-4089-a2a0-7a98bbc2d0bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [03:59<00:00, 836.37it/s]\n"
          ]
        }
      ],
      "source": [
        "# Get POS TAGS for all sentences in words_list\n",
        "tagged_sentences = []\n",
        "for sentence in tqdm(words_list):\n",
        "  tagged_sentence = pos_tag(sentence)\n",
        "  tagged_sentences.append(tagged_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0p3zzPD6G0-",
        "outputId": "6239101d-b599-4e74-aba9-cb98d7f706ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [00:05<00:00, 38119.33it/s]\n"
          ]
        }
      ],
      "source": [
        "# Separate lists of POS and append in respective lists\n",
        "# Noun -> NN/NNS, Verb -> VB, Adjective -> JJ, Adverb -> RP/RB, Numeric -> CD, Determiner -> DT | however D and C do not work in WordNet\n",
        "pos_tagged_sentences = []\n",
        "for tagged_words in tqdm(tagged_sentences):\n",
        "  pos_words = {'NOUN': [], 'VERB': [], 'ADJ': [], 'ADV': [], 'DET': [], 'NUM': []}\n",
        "  for word, pos in tagged_words:\n",
        "    if pos.startswith('N'):\n",
        "        pos_words['NOUN'].append(word)\n",
        "    elif pos.startswith('V'):\n",
        "        pos_words['VERB'].append(word)\n",
        "    elif pos.startswith('J'):\n",
        "        pos_words['ADJ'].append(word)\n",
        "    elif pos.startswith('R'):\n",
        "        pos_words['ADV'].append(word)\n",
        "  pos_tagged_sentences.append(pos_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "r6mBwWPflqMa"
      },
      "outputs": [],
      "source": [
        "# Function to get Sentences along with POS Tags\n",
        "def get_pos_tagged_sentences(words_list):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    tagged_sentences = []\n",
        "    pos_tagged_sentences = []\n",
        "\n",
        "    print(f\"Getting POS Tags for each sentence\")\n",
        "    for sentence in tqdm(words_list):\n",
        "        tagged_sentence = pos_tag(sentence)\n",
        "        tagged_sentences.append(tagged_sentence)\n",
        "\n",
        "    print(f\"Getting POS Tags Lists each sentence\")\n",
        "    for tagged_words in tqdm(tagged_sentences):\n",
        "        pos_words = {'NOUN': [], 'VERB': [], 'ADJ': [], 'ADV': [], 'DET': [], 'NUM': []}\n",
        "        for word, pos in tagged_words:\n",
        "            if pos.startswith('N'):\n",
        "                pos_words['NOUN'].append(word)\n",
        "            elif pos.startswith('V'):\n",
        "                pos_words['VERB'].append(word)\n",
        "            elif pos.startswith('J'):\n",
        "                pos_words['ADJ'].append(word)\n",
        "            elif pos.startswith('R'):\n",
        "                pos_words['ADV'].append(word)\n",
        "        pos_tagged_sentences.append(pos_words)\n",
        "\n",
        "    return pos_tagged_sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT76AnMslrOp",
        "outputId": "84f06d9c-c487-408c-e73f-536e77161efa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [03:30<00:00, 951.45it/s] \n",
            "100%|██████████| 200000/200000 [00:04<00:00, 48988.35it/s]\n"
          ]
        }
      ],
      "source": [
        "pos_tagged_sentences = get_pos_tagged_sentences(words_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGMJqxb86GwP",
        "outputId": "cb14216a-3215-47e4-89ea-6b89e49cc26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "728.0\n"
          ]
        }
      ],
      "source": [
        "sense_combination = 0\n",
        "for pos, words in pos_tagged_sentences[2].items():\n",
        "  for word in words:\n",
        "    synsets = wn.synsets(word, pos=pos[0].lower())\n",
        "    if synsets:\n",
        "      num_senses = len(synsets)\n",
        "      sense_combination += math.log(num_senses)\n",
        "      # print(sense_combination)\n",
        "sense_combination = math.exp(sense_combination)\n",
        "print(sense_combination)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfkq7GGPKFhX",
        "outputId": "ebbf5a30-56d1-447e-cfa4-45a8b5b057f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3333333333333333\n",
            "0.043478260869565216\n"
          ]
        }
      ],
      "source": [
        "# Calculate closest and farmost sense of a given word from WordNet SYNSETS by finding all other senses\n",
        "path_similarities = []\n",
        "for words in pos_tagged_sentences[2].values():\n",
        "  for word in words:\n",
        "    synsets = wn.synsets(word)\n",
        "    if synsets:\n",
        "      # for each sense of same word, find similarity\n",
        "      for synset in synsets:\n",
        "        # Compare the similarity of our word sense with other word senses (of same word)\n",
        "        similarities = [synset.path_similarity(other) for other in synsets if other != synset and other.path_similarity(synset)]\n",
        "        if similarities:\n",
        "          path_similarities.extend(similarities)\n",
        "\n",
        "sense_farmost = max(path_similarities) if path_similarities else None\n",
        "sense_closest = min(path_similarities) if path_similarities else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ibaTzhp6Gtw",
        "outputId": "0f010683-b38f-46ee-841a-c132350d9460"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [00:21<00:00, 9298.80it/s] \n"
          ]
        }
      ],
      "source": [
        "# Get a Sense combination score by the FORMULA in paper using WordNet - SYNSET -> Sense Combination Feature\n",
        "sense_combination_list = []\n",
        "for sentence in tqdm(pos_tagged_sentences):\n",
        "  sense_combination = 0\n",
        "  for pos, words in sentence.items():\n",
        "    for word in words:\n",
        "      synsets = wn.synsets(word, pos=pos[0].lower())\n",
        "      if synsets:\n",
        "        num_senses = len(synsets)\n",
        "        sense_combination += math.log(num_senses) ##################### CHECK FORMULA ###################\n",
        "  sense_combination = math.exp(sense_combination)\n",
        "  sense_combination_list.append(sense_combination)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "ku0feJCu6GpQ",
        "outputId": "b7a5431c-ad50-4422-d29e-05750cb2e19d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 31418/200000 [1:10:59<6:20:56,  7.38it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-9588543aac55>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynsets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0;31m# Compare the similarity of our word sense with other word senses (of same word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynsets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpath_similarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-9588543aac55>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynsets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0;31m# Compare the similarity of our word sense with other word senses (of same word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m           \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msynsets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msynset\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mpath_similarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mpath_similarity\u001b[0;34m(self, other, verbose, simulate_root)\u001b[0m\n\u001b[1;32m    869\u001b[0m         distance = self.shortest_path_distance(\n\u001b[1;32m    870\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0msimulate_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimulate_root\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_needs_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_needs_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         )\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_needs_root\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_needs_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNOUN\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wordnet_corpus_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"1.6\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36mget_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mADJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1440\u001b[0m             \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"Word[nN]et (\\d+|\\d+\\.\\d+) Copyright\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;34m\"\"\"Return the next decoded line from the underlying stream.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0mstartpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbytebuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0mnew_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;31m# If we're at a '\\r', then read one extra character, since\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Get Sense Farmost and Closest Path Similarity\n",
        "sense_farmost_list = []\n",
        "sense_closest_list = []\n",
        "\n",
        "for sentence in tqdm(pos_tagged_sentences):\n",
        "  path_similarities = []\n",
        "  for words in sentence.values():\n",
        "    for word in words:\n",
        "      synsets = wn.synsets(word)\n",
        "      if synsets:\n",
        "        # for each sense of same word, find similarity\n",
        "        for synset in synsets:\n",
        "          # Compare the similarity of our word sense with other word senses (of same word)\n",
        "          similarities = [synset.path_similarity(other) for other in synsets if other != synset and other.path_similarity(synset)]\n",
        "          if similarities:\n",
        "            path_similarities.extend(similarities)\n",
        "  sense_farmost = max(path_similarities) if path_similarities else None\n",
        "  sense_closest = min(path_similarities) if path_similarities else None\n",
        "  sense_farmost_list.append(sense_farmost)\n",
        "  sense_closest_list.append(sense_closest)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h8jxvjr4tLb"
      },
      "source": [
        "### Phonetic Style"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RNpKFZVrnj0"
      },
      "source": [
        "### For all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "UB2gq5DirLQm"
      },
      "outputs": [],
      "source": [
        "d = cmudict.dict()\n",
        "\n",
        "\n",
        "# Function to get Phonetic representations of word\n",
        "def get_phonemes(word):\n",
        "    \"\"\"\n",
        "    Get phonetic representation of a word from CMU Pronouncing Dictionary\n",
        "    \"\"\"\n",
        "    return d[word][0] if word in d else None\n",
        "\n",
        "\n",
        "# Function to get alliteration and rhyme\n",
        "def detect_alliteration_rhyme(words):\n",
        "    alliteration_chains = 0\n",
        "    max_alliteration_chain_length = 0\n",
        "\n",
        "    rhyme_chains = 0\n",
        "    max_rhyme_chain_length = 0\n",
        "\n",
        "    prev_phoneme = None\n",
        "    alliteration_chain_length = 1\n",
        "    rhyme_chain_length = 1\n",
        "\n",
        "    for word in words:\n",
        "        phonemes = get_phonemes(word)\n",
        "\n",
        "        if phonemes:\n",
        "            first_phoneme = phonemes[0]\n",
        "            last_phoneme = phonemes[-1]\n",
        "\n",
        "            if prev_phoneme and first_phoneme == prev_phoneme:\n",
        "                alliteration_chain_length += 1\n",
        "            else:\n",
        "                max_alliteration_chain_length = max(max_alliteration_chain_length, alliteration_chain_length)\n",
        "                if alliteration_chain_length > 1:\n",
        "                    alliteration_chains += 1\n",
        "                alliteration_chain_length = 1\n",
        "\n",
        "            if prev_phoneme and last_phoneme == prev_phoneme:\n",
        "                rhyme_chain_length += 1\n",
        "            else:\n",
        "                max_rhyme_chain_length = max(max_rhyme_chain_length, rhyme_chain_length)\n",
        "                if rhyme_chain_length > 1:\n",
        "                    rhyme_chains += 1\n",
        "                rhyme_chain_length = 1\n",
        "\n",
        "            prev_phoneme = last_phoneme\n",
        "\n",
        "    return alliteration_chains, max_alliteration_chain_length, rhyme_chains, max_rhyme_chain_length\n",
        "\n",
        "\n",
        "# Get Phonetic Style\n",
        "def phonetic_style(words_list):\n",
        "  alliteration_list = []\n",
        "  max_alliteration_list = []\n",
        "  rhyme_list = []\n",
        "  max_rhyme_list = []\n",
        "\n",
        "  for sentence in tqdm(words_list):\n",
        "    alliteration_chains, max_alliteration_chain_length, rhyme_chains, max_rhyme_chain_length = detect_alliteration_rhyme(sentence)\n",
        "\n",
        "    alliteration_list.append(alliteration_chains)\n",
        "    max_alliteration_list.append(max_alliteration_chain_length)\n",
        "    rhyme_list.append(rhyme_chains)\n",
        "    max_rhyme_list.append(max_rhyme_chain_length)\n",
        "\n",
        "  return alliteration_list, max_alliteration_list, rhyme_list, max_rhyme_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q0W3m3RsuNL",
        "outputId": "9fecd193-f7b7-4c22-cb3e-c81fe4699217"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [00:05<00:00, 36318.80it/s]\n"
          ]
        }
      ],
      "source": [
        "alliteration, max_alliteration, rhyme, max_rhyme = phonetic_style(words_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgU3Fb9KsyRL",
        "outputId": "13dd5ce6-371e-4f9e-e214-673adc5a75a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "200000"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(rhyme)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzKn4zfSs42U",
        "outputId": "2051c3ee-7809-4991-de9b-b8b206bd5323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values: [0, 1, 2, 3, 4, 5, 6, 11]\n"
          ]
        }
      ],
      "source": [
        "# Get unique values using set()\n",
        "unique_values = list(set(max_rhyme))\n",
        "\n",
        "# Print the unique values\n",
        "print(\"Unique values:\", unique_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up4UK6tKvsTP",
        "outputId": "60e678c6-78d3-483c-e9ff-06a0f1a4bde1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values: [0, 1, 2, 3, 4, 5]\n"
          ]
        }
      ],
      "source": [
        "# Get unique values using set()\n",
        "unique_values = list(set(rhyme))\n",
        "\n",
        "# Print the unique values\n",
        "print(\"Unique values:\", unique_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8OuVJ6JvsKR",
        "outputId": "8d7cfa9f-e420-47b9-8b65-be7e96668676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values: [0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "# Get unique values using set()\n",
        "unique_values = list(set(max_alliteration))\n",
        "\n",
        "# Print the unique values\n",
        "print(\"Unique values:\", unique_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcqxF0vMvsH7",
        "outputId": "0ce0be0b-dc61-4811-8e42-4a823dd25725"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique values: [0, 1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "# Get unique values using set()\n",
        "unique_values = list(set(alliteration))\n",
        "\n",
        "# Print the unique values\n",
        "print(\"Unique values:\", unique_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "QBHCPxZmv4P2",
        "outputId": "fb69a90c-ec4a-43f5-c729-2eb6ff3ff705"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3e6bc83d-d429-4c9f-907e-ebbe65ca7619\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alliteration</th>\n",
              "      <th>max_alliteration</th>\n",
              "      <th>rhyme</th>\n",
              "      <th>max_rhyme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e6bc83d-d429-4c9f-907e-ebbe65ca7619')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e6bc83d-d429-4c9f-907e-ebbe65ca7619 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e6bc83d-d429-4c9f-907e-ebbe65ca7619');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1c325557-f2d9-424b-8b11-d2c84e540cec\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c325557-f2d9-424b-8b11-d2c84e540cec')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1c325557-f2d9-424b-8b11-d2c84e540cec button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        alliteration  max_alliteration  rhyme  max_rhyme\n",
              "0                  0                 1      0          1\n",
              "1                  0                 1      0          1\n",
              "2                  0                 1      1          2\n",
              "3                  0                 1      0          1\n",
              "4                  0                 1      0          1\n",
              "...              ...               ...    ...        ...\n",
              "199995             0                 1      0          1\n",
              "199996             0                 1      1          2\n",
              "199997             1                 2      1          2\n",
              "199998             0                 1      0          1\n",
              "199999             0                 1      0          1\n",
              "\n",
              "[200000 rows x 4 columns]"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# alliteration, max_alliteration, rhyme, max_rhyme\n",
        "ps_df = pd.DataFrame({'alliteration': alliteration,\n",
        "    'max_alliteration': max_alliteration,\n",
        "    'rhyme': rhyme,\n",
        "    'max_rhyme': max_rhyme\n",
        "})\n",
        "ps_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJIhQQAfwS4B",
        "outputId": "c55d96ce-ec75-4d9c-e98d-90722517ea7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5510333333333334"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "train_data_X, test_data_X, train_data_Y, test_data_Y = train_test_split(ps_df, labels, test_size=0.3)\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(train_data_X, train_data_Y)\n",
        "model.score(train_data_X, train_data_Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0NWRvBwwc40",
        "outputId": "215d74e0-4b56-4d99-f0b8-d011e9347a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.67      0.54      0.60     86933\n",
            "        True       0.43      0.56      0.49     53067\n",
            "\n",
            "    accuracy                           0.55    140000\n",
            "   macro avg       0.55      0.55      0.54    140000\n",
            "weighted avg       0.58      0.55      0.56    140000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(test_data_X)\n",
        "print(classification_report(preds, test_data_Y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3Qm6a9swgNr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
